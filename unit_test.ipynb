{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing for Data Science In Python\n",
    "\n",
    "1. Unit testing basics\n",
    "2. Intermediate unit testing\n",
    "3. Test Organization and Execution\n",
    "4. Testing Models, Plots and Much More\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "## 1. Unit Testing Basics\n",
    "\n",
    "- TODO\n",
    "    - pytest를 활용한 기본적인 실행\n",
    "    - 실행 결과 이해\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "* Life cycle of a function  \n",
    "\n",
    "![life_cycle_of_a_function](https://raw.githubusercontent.com/SSinyu/PlayGround/master/fig/life_cycle_of_a_function.PNG)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시) 특정 주택에 대한 면적과 가격 정보가 tab으로 구분되어 문자열로 기록  \n",
    "\n",
    "|area  price|\n",
    "|----|\n",
    "|\"2,081\\t314,942\\n\"|\n",
    "|\"1,059\\t186,606\\n\"|\n",
    "|\"\\t293,410\\n\"|\n",
    "|\"1,463238,765\\n\"|  \n",
    "\n",
    "<br/>  \n",
    "\n",
    "`row_to_list`  \n",
    "-> `row_to_list(\"2,081\\t314,942\\n\")`    return: [\"2,081\", \"314,942\"]  \n",
    "-> `row_to_list(\"\\t293,410\\n\")`         return: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2,081', '314,942']\n",
      "['1,059', '186,606']\n",
      "['', '293,410']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_helpers import row_to_list\n",
    "\n",
    "print(row_to_list(\"2,081\\t314,942\\n\"))\n",
    "print(row_to_list(\"1,059\\t186,606\\n\"))\n",
    "print(row_to_list(\"\\t293,410\\n\"))\n",
    "print(row_to_list(\"1,463238,765\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pytest로 unit test 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_row_to_list.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_row_to_list.py\n",
    "import pytest\n",
    "from row_to_list import row_to_list\n",
    "\n",
    "def test_for_clean_row():\n",
    "    assert row_to_list(\"2,081\\t314,942\\n\") == [\"2,081\", \"314,942\"]\n",
    "\n",
    "def test_for_missing_area():\n",
    "    assert row_to_list(\"\\t293,410\\n\") is None\n",
    "\n",
    "def test_for_missing_tab():\n",
    "    assert row_to_list(\"1,463238,765\\n\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0\n",
      "Matplotlib: 3.5.2\n",
      "Freetype: 2.6.1\n",
      "rootdir: /home/ubuntu/ssinyu/FDB\n",
      "plugins: mock-3.10.0, mpl-0.16.1\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "test_row_to_list.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                  [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ test_for_missing_area _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_for_missing_area\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m row_to_list(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m293,410\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert ['', '293,410'] is None\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where ['', '293,410'] = row_to_list('\\t293,410\\n')\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_row_to_list.py\u001b[0m:8: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_row_to_list.py::\u001b[1mtest_for_missing_area\u001b[0m - AssertionError: assert ['', '293,410'] is None\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m2 passed\u001b[0m\u001b[31m in 0.22s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_row_to_list.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unit test script를 통해 특정 기능을 빠르게 파악할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import pytest\n",
      "\n",
      "from mystery_function import mystery_function\n",
      "\n",
      "def test_on_clean_data():\n",
      "    assert np.array_equal(mystery_function(\"example_clean_data.txt\", num_columns=2), np.array([[2081.0, 314942.0], [1059.0, 186606.0]]))\n"
     ]
    }
   ],
   "source": [
    "!cat test_mystery_function.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "  \n",
    "## 2. Intermediate unit testing\n",
    "\n",
    "- TODO\n",
    "    - pytest 추가 기능\n",
    "    - test 범위 설정\n",
    "    - Test Driven Development (TDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "* `assert {boolen_experssion}, {message}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "One is not equal to two",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/ssinyu/FDB/unit_test.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B210.106.99.200/home/ubuntu/ssinyu/FDB/unit_test.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mOne is not equal to two\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: One is not equal to two"
     ]
    }
   ],
   "source": [
    "assert 1 == 2, \"One is not equal to two\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_row_to_list.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_row_to_list.py\n",
    "import pytest\n",
    "from row_to_list import row_to_list\n",
    "\n",
    "def test_for_clean_row():\n",
    "    assert row_to_list(\"2,081\\t314,942\\n\") == [\"2,081\", \"314,942\"]\n",
    "\n",
    "def test_for_missing_area():\n",
    "    assert row_to_list(\"\\t293,410\\n\") is None # actually -> [\"\", \"293,410\"]\n",
    "\n",
    "def test_for_missing_tab():\n",
    "    assert row_to_list(\"1,463238,765\\n\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0\n",
      "Matplotlib: 3.5.2\n",
      "Freetype: 2.6.1\n",
      "rootdir: /home/ubuntu/ssinyu/FDB\n",
      "plugins: mock-3.10.0, mpl-0.16.1\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "test_row_to_list.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                  [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ test_for_missing_area _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_for_missing_area\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m row_to_list(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m293,410\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[90m# actually -> [\"\", \"293,410\"]\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert ['', '293,410'] is None\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where ['', '293,410'] = row_to_list('\\t293,410\\n')\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_row_to_list.py\u001b[0m:8: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_row_to_list.py::\u001b[1mtest_for_missing_area\u001b[0m - AssertionError: assert ['', '293,410'] is None\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m2 passed\u001b[0m\u001b[31m in 0.23s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_row_to_list.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_row_to_list.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_row_to_list.py\n",
    "import pytest\n",
    "from row_to_list import row_to_list\n",
    "\n",
    "test_for_missiong_area_error_message = \"row_to_list('\\\\t293,410\\\\n') returned ['', '293,410'] instead of None\"\n",
    "\n",
    "def test_for_clean_row():\n",
    "    assert row_to_list(\"2,081\\t314,942\\n\") == [\"2,081\", \"314,942\"]\n",
    "\n",
    "def test_for_missing_area():\n",
    "    assert row_to_list(\"\\t293,410\\n\") is None, test_for_missiong_area_error_message\n",
    "\n",
    "def test_for_missing_tab():\n",
    "    assert row_to_list(\"1,463238,765\\n\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0\n",
      "Matplotlib: 3.5.2\n",
      "Freetype: 2.6.1\n",
      "rootdir: /home/ubuntu/ssinyu/FDB\n",
      "plugins: mock-3.10.0, mpl-0.16.1\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "test_row_to_list.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                  [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ test_for_missing_area _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_for_missing_area\u001b[39;49;00m():\n",
      ">       \u001b[94massert\u001b[39;49;00m row_to_list(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m293,410\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m, test_for_missiong_area_error_message\n",
      "\u001b[1m\u001b[31mE       AssertionError: row_to_list('\\t293,410\\n') returned ['', '293,410'] instead of None\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert ['', '293,410'] is None\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where ['', '293,410'] = row_to_list('\\t293,410\\n')\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_row_to_list.py\u001b[0m:10: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_row_to_list.py::\u001b[1mtest_for_missing_area\u001b[0m - AssertionError: row_to_list('\\t293,410\\n') returned ['', '293,410'] instead...\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m2 passed\u001b[0m\u001b[31m in 0.22s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_row_to_list.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python은 실수를 부동소수점 방식으로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "print(.1 + .1 + .1 == .3)\n",
    "print(.1 + .1 + .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/ssinyu/FDB/unit_test.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B210.106.99.200/home/ubuntu/ssinyu/FDB/unit_test.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m.1\u001b[39m \u001b[39m+\u001b[39m \u001b[39m.1\u001b[39m \u001b[39m+\u001b[39m \u001b[39m.1\u001b[39m \u001b[39m==\u001b[39m \u001b[39m.3\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert .1 + .1 + .1 == .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "assert .1 + .1 + .1 == pytest.approx(.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다양한 자료형 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "assert (0.1 + 0.2, 0.2 + 0.4) == pytest.approx((0.3, 0.6))\n",
    "assert {'a': 0.1 + 0.2, 'b': 0.2 + 0.4} == pytest.approx({'a': 0.3, 'b': 0.6})\n",
    "assert np.array([0.1, 0.2]) + np.array([0.2, 0.4]) == pytest.approx(np.array([0.3, 0.6])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 소수 여섯째 자리 까지만 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pytest.approx(6.1234567) == 6.123456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다수의 assert 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import split_into_training_and_testing_sets\n",
    "\n",
    "def test_on_six_rows():\n",
    "    example_argument = np.array([\n",
    "        [2081.0, 314942.0], \n",
    "        [1059.0, 186606.0],\n",
    "        [1148.0, 206186.0], \n",
    "        [1506.0, 248419.0],\n",
    "        [1210.0, 214114.0], \n",
    "        [1697.0, 277794.0]\n",
    "    ])\n",
    "    \n",
    "    expected_training_array_num_rows = 4\n",
    "    expected_testing_array_num_rows = 2\n",
    "    \n",
    "    actual = split_into_training_and_testing_sets(example_argument) \n",
    "    # Returns 2-tuple of arrays (training_set, testing_set)\n",
    "    # Training set contains 75% randomly selected rows of array\n",
    "    \n",
    "    assert actual[0].shape[0] == expected_training_array_num_rows, \\\n",
    "            \"The actual number of rows in the training array is not {}\".format(expected_training_array_num_rows)\n",
    "    \n",
    "    assert actual[1].shape[0] == expected_testing_array_num_rows, \\\n",
    "            \"The actual number of rows in the testing array is not {}\".format(expected_testing_array_num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 특정한 에러를 가져야 하는 경우 `pytest.raises()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument data_array must be two dimensional. Got 1 dimensional array instead!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/ssinyu/FDB/unit_test.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B210.106.99.200/home/ubuntu/ssinyu/FDB/unit_test.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m example_argument \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m2081\u001b[39m, \u001b[39m314942\u001b[39m, \u001b[39m1059\u001b[39m, \u001b[39m186606\u001b[39m, \u001b[39m1148\u001b[39m, \u001b[39m206186\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B210.106.99.200/home/ubuntu/ssinyu/FDB/unit_test.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m split_into_training_and_testing_sets(example_argument)\n",
      "File \u001b[0;32m~/ssinyu/FDB/train.py:6\u001b[0m, in \u001b[0;36msplit_into_training_and_testing_sets\u001b[0;34m(data_array)\u001b[0m\n\u001b[1;32m      4\u001b[0m dim \u001b[39m=\u001b[39m data_array\u001b[39m.\u001b[39mndim\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m dim \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mArgument data_array must be two dimensional. Got \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m dimensional array instead!\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(dim))\n\u001b[1;32m      7\u001b[0m num_rows \u001b[39m=\u001b[39m data_array\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m num_rows \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Argument data_array must be two dimensional. Got 1 dimensional array instead!"
     ]
    }
   ],
   "source": [
    "example_argument = np.array([2081, 314942, 1059, 186606, 1148, 206186])\n",
    "\n",
    "split_into_training_and_testing_sets(example_argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_argument = np.array([2081, 314942, 1059, 186606, 1148, 206186])\n",
    "\n",
    "with pytest.raises(ValueError):\n",
    "    split_into_training_and_testing_sets(example_argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "Failed",
     "evalue": "DID NOT RAISE <class 'ValueError'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailed\u001b[0m                                    Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/ssinyu/FDB/unit_test.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B210.106.99.200/home/ubuntu/ssinyu/FDB/unit_test.ipynb#Y115sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m pytest\u001b[39m.\u001b[39mraises(\u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B210.106.99.200/home/ubuntu/ssinyu/FDB/unit_test.ipynb#Y115sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ssinyu/lib/python3.8/site-packages/_pytest/outcomes.py:194\u001b[0m, in \u001b[0;36mfail\u001b[0;34m(reason, pytrace, msg)\u001b[0m\n\u001b[1;32m    192\u001b[0m __tracebackhide__ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    193\u001b[0m reason \u001b[39m=\u001b[39m _resolve_msg_to_reason(\u001b[39m\"\u001b[39m\u001b[39mfail\u001b[39m\u001b[39m\"\u001b[39m, reason, msg)\n\u001b[0;32m--> 194\u001b[0m \u001b[39mraise\u001b[39;00m Failed(msg\u001b[39m=\u001b[39mreason, pytrace\u001b[39m=\u001b[39mpytrace)\n",
      "\u001b[0;31mFailed\u001b[0m: DID NOT RAISE <class 'ValueError'>"
     ]
    }
   ],
   "source": [
    "with pytest.raises(ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_valueerror_on_one_dimensional_argument.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_valueerror_on_one_dimensional_argument.py\n",
    "\n",
    "import pytest\n",
    "import numpy as np\n",
    "from train import split_into_training_and_testing_sets\n",
    "\n",
    "def test_valueerror_on_one_dimensional_argument():\n",
    "    example_argument = np.array([2081, 314942, 1059, 186606, 1148, 206186])\n",
    "    \n",
    "    with pytest.raises(ValueError) as exception_info:\n",
    "        split_into_training_and_testing_sets(example_argument)\n",
    "        \n",
    "        assert exception_info.match(\n",
    "            \"Argument data array must be two dimensional. \"\n",
    "            \"Got 1 dimensional array instead!\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0\n",
      "Matplotlib: 3.5.2\n",
      "Freetype: 2.6.1\n",
      "rootdir: /home/ubuntu/ssinyu/FDB\n",
      "plugins: mock-3.10.0, mpl-0.16.1\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_valueerror_on_one_dimensional_argument.py \u001b[32m.\u001b[0m\u001b[32m                         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.17s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_valueerror_on_one_dimensional_argument.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 얼마나 많은 조건을 테스트 해야 할까?\n",
    "\n",
    "예) 데이터를 입력 받아 train 및 test를 3:1로 분할\n",
    "```\n",
    "example_argument = np.array([\n",
    "        [2081.0, 314942.0], \n",
    "        [1059.0, 186606.0],\n",
    "        [1148.0, 206186.0], \n",
    "        [1506.0, 248419.0],\n",
    "        [1210.0, 214114.0], \n",
    "        [1697.0, 277794.0]\n",
    "    ])\n",
    "\n",
    "train, test = split_into_training_and_testing_sets(example_argument)  \n",
    "```\n",
    "\n",
    "|n of input rows|n of train rows|n of test rows|\n",
    "|:----|:----|:----|\n",
    "|8|6|2|\n",
    "|10|7|3|\n",
    "|23|17|6|\n",
    "|...|...|...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "* 3가지 유형을 테스트 할 것\n",
    "    * Bad arguments\n",
    "    * Special arguments\n",
    "    * Normal arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad arguments\n",
    "example_argument1 = np.array([2081, 314942, 1059, 186606, 1148, 206186])\n",
    "with pytest.raises(ValueError):\n",
    "    split_into_training_and_testing_sets(example_argument1)\n",
    "\n",
    "example_argument2 = np.array([[845.0, 31036.0]])\n",
    "with pytest.raises(ValueError):\n",
    "    split_into_training_and_testing_sets(example_argument2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![argument_type](https://raw.githubusercontent.com/SSinyu/PlayGround/master/fig/argument_type.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시)  \n",
    "\n",
    "`row_to_list(\"2,081\\t314,942\\n\")`    return: [\"2,081\", \"314,942\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boundary Value\n",
    "  \n",
    "![boundary_value](https://raw.githubusercontent.com/SSinyu/PlayGround/master/fig/boundary_value.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from preprocessing_helpers import row_to_list\n",
    "\n",
    "def test_on_no_tab_no_missing_value():    # (0, 0) boundary value\n",
    "    # Assign actual to the return value for the argument \"123\\n\"\n",
    "    actual = row_to_list(\"123\\n\")\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_two_tabs_no_missing_value():    # (2, 0) boundary value\n",
    "    actual = row_to_list(\"123\\t4,567\\t89\\n\")\n",
    "    # Complete the assert statement\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)\n",
    "    \n",
    "def test_on_one_tab_with_missing_value():    # (1, 1) boundary value\n",
    "    actual = row_to_list(\"\\t4,567\\n\")\n",
    "    # Format the failure message\n",
    "    assert actual is None, \"Expected: None, Actual: {0}\".format(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "* Test Driven Development (TDD)\n",
    "    * 기능 개발 전에 unit test 부터 작성한다  \n",
    "    -> unit test를 미루지 않게 된다  \n",
    "    -> 명확하게 필요한 기능을 정의하여 개발에 도움이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>  \n",
    "\n",
    "예시) 천단위 구분자(,) 문자열을 숫자로 변환 (`convert_to_int`)\n",
    "\n",
    "\n",
    "-> `convert_to_int(\"2,081\")`    return: 2081  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_convert_to_int.py\n",
    "\n",
    "import pytest\n",
    "from preprocessing_helpers import convert_to_int\n",
    "\n",
    "def test_with_no_comma():\n",
    "    ...\n",
    "\n",
    "def test_with_one_comma():\n",
    "    ...\n",
    "\n",
    "def test_with_two_commas():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "  \n",
    "## 3. Test Organization and Execution\n",
    "\n",
    "- TODO\n",
    "    - 체계적인 unit test 구성\n",
    "    - 특정 조건으로 unit test 수행\n",
    "    - 일부 기능의 test 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "* Project structure example\n",
    "    * \"test_\" 로 시작하는 이름의 파일을 테스트 모듈로 식별\n",
    "  \n",
    "```\n",
    "    src/\n",
    "    ├── data/\n",
    "    │   ├── __init__.py\n",
    "    │   └── preprocessing_helpers.py\n",
    "    │\n",
    "    ├── features/\n",
    "    │   ├── __init__.py\n",
    "    │   └── as_numpy.py\n",
    "    │\n",
    "    ├── models/\n",
    "    │   ├── __init__.py\n",
    "    │   └── train.py\n",
    "    │\n",
    "    │\n",
    "    tests/\n",
    "    ├── data/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_preprocessing_helpers.py\n",
    "    │\n",
    "    ├── features/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_as_numpy.py\n",
    "    │\n",
    "    └── models/\n",
    "        ├── __init__.py\n",
    "        └── test_train.py   \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* class를 사용해 function 단위로 분리하여 test\n",
    "    * \"Test\"로 시작하는 class 이름을 테스트 class로 식별\n",
    "    * \"test_\"로 시작하는 function 이름을 테스트 function으로 식별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_preprocessing_helpers.py\n",
    "import pytest\n",
    "from data.preprocessing_helpers import row_to_list, conver_to_int\n",
    "\n",
    "def test_on_no_tab_no_missing_value():\n",
    "    ...\n",
    "\n",
    "def test_on_two_tabs_no_missing_value():\n",
    "    ...\n",
    "\n",
    "def test_with_no_comma():\n",
    "    ...\n",
    "\n",
    "def test_with_one_comma():\n",
    "    ...\n",
    "\n",
    "...\n",
    "\n",
    "# (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_preprocessing_helpers.py\n",
    "import pytest\n",
    "from data.preprocessing_helpers import row_to_list, conver_to_int\n",
    "\n",
    "class TestRowToList:\n",
    "    def test_on_no_tab_no_missing_value(self):\n",
    "        ...\n",
    "\n",
    "    def test_on_two_tabs_no_missing_value(self):\n",
    "        ...\n",
    "\n",
    "    ...\n",
    "\n",
    "class TestConvertToInt:\n",
    "    def test_with_no_comma(self):\n",
    "        ...\n",
    "\n",
    "    def test_with_one_comma(self):\n",
    "        ...\n",
    "\n",
    "    ...\n",
    "\n",
    "# (O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시 1) `test_preprocessing_helpers.py` 만 실행하기\n",
    "\n",
    "-> `pytest data/test_preprocessing_helpers.py`\n",
    "\n",
    "```\n",
    "    tests/\n",
    "    ├── data/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_preprocessing_helpers.py\n",
    "    │               ├── TestRowToList (class)\n",
    "    │               │        ├── test_on_normal_argument_1 (function)\n",
    "    │               │        ├── test_on_normal_argument_2 (function)\n",
    "    │               │        └── ...\n",
    "    │               └── TestConvertToInt (class)\n",
    "    │                        └── ...\n",
    "    ├── features/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_as_numpy.py\n",
    "    │\n",
    "    └── models/\n",
    "        ├── __init__.py\n",
    "        └── test_train.py   \n",
    "\n",
    "```\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시 2) `TestConvertToInt (class)` 또는 `test_on_string_with_one_comma (fucntion)` 만 실행하기\n",
    "\n",
    "-> `pytest data/test_preprocessing_helpers.py::TestConvertToInt`  \n",
    "-> `pytest data/test_preprocessing_helpers.py::TestConvertToInt::test_on_string_with_one_comma`\n",
    "\n",
    "```\n",
    "    tests/\n",
    "    ├── data/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_preprocessing_helpers.py\n",
    "    │               ├── TestRowToList (class)\n",
    "    │               └── TestConvertToInt (class)\n",
    "    │                        ├── test_on_string_with_one_comma (function)\n",
    "    |                        └── ...\n",
    "    ├── features/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_as_numpy.py\n",
    "    │\n",
    "    └── models/\n",
    "        ├── __init__.py\n",
    "        └── test_train.py   \n",
    "\n",
    "```\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시 3) 키워드 표현식으로 `TestSplitIntoTrainingAndTestingSets (class)` 실행하기\n",
    "\n",
    "-> `pytest -k \"TestSplitIntoTrainingAndTestingSets\"`  \n",
    "-> `pytest -k \"TestSplit\"`\n",
    "\n",
    "\n",
    "```\n",
    "    tests/\n",
    "    ├── data/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_preprocessing_helpers.py\n",
    "    │\n",
    "    ├── features/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_as_numpy.py\n",
    "    │\n",
    "    └── models/\n",
    "        ├── __init__.py\n",
    "        └── test_train.py   \n",
    "                    └── TestSplitIntoTrainingAndTestingSets (class)\n",
    "\n",
    "```\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시 4) 키워드 표현식으로 `TestSplitIntoTrainingAndTestingSets (class)`의 `test_on_one_row` 제외 나머지 실행하기\n",
    "\n",
    "-> `pytest -k \"TestSplit and not test_on_one_row\"`  \n",
    "\n",
    "\n",
    "```\n",
    "    tests/\n",
    "    ├── data/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_preprocessing_helpers.py\n",
    "    │\n",
    "    ├── features/\n",
    "    │   ├── __init__.py\n",
    "    │   └── test_as_numpy.py\n",
    "    │\n",
    "    └── models/\n",
    "        ├── __init__.py\n",
    "        └── test_train.py   \n",
    "                    └── TestSplitIntoTrainingAndTestingSets (class)\n",
    "                                    ├── test_on_empty_row.py\n",
    "                                    ├── test_on_one_row.py\n",
    "                                    └── test_on_two_row.py   \n",
    "\n",
    "```\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 실패할 테스트를 미리 알려주기 (using TDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "class TestTrainModel:\n",
    "    @pytest.mark.xfail\n",
    "    def test_on_linear_data(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 특정 조건에서 테스트 건너뛰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "class TestConvertToInt:\n",
    "    @pytest.mark.skipif(sys.version_info > (2, 7), reason=\"requires python 3.7 or higher\")\n",
    "    def test_with_no_comma(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_tmp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_tmp.py\n",
    "import pytest\n",
    "import sys\n",
    "\n",
    "class TestTrainModel:\n",
    "    @pytest.mark.xfail(reason=\"not implemented\")\n",
    "    def test_on_linear_data(self):\n",
    "        assert False\n",
    "\n",
    "\n",
    "class TestConvertToInt:\n",
    "    @pytest.mark.skipif(sys.version_info >= (2, 7), reason=\"requires python 3.7 or higher\") \n",
    "    def test_with_no_comma(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0\n",
      "Matplotlib: 3.5.2\n",
      "Freetype: 2.6.1\n",
      "rootdir: /home/ubuntu/ssinyu/FDB\n",
      "plugins: mock-3.10.0, mpl-0.16.1\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_tmp.py \u001b[33mx\u001b[0m\u001b[33ms\u001b[0m\u001b[33m                                                           [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m======================== \u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m1 xfailed\u001b[0m\u001b[33m in 0.18s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_tmp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "* 테스트를 건너뛰는 이유 표시하기\n",
    "    * `pytest -rs`\n",
    "    * `pytest -rx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0\n",
      "Matplotlib: 3.5.2\n",
      "Freetype: 2.6.1\n",
      "rootdir: /home/ubuntu/ssinyu/FDB\n",
      "plugins: mock-3.10.0, mpl-0.16.1\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_tmp.py \u001b[33mx\u001b[0m\u001b[33ms\u001b[0m\u001b[33m                                                           [100%]\u001b[0m\n",
      "\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[33mSKIPPED\u001b[0m [1] test_tmp.py:11: requires python 3.7 or higher\n",
      "\u001b[33m======================== \u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m1 xfailed\u001b[0m\u001b[33m in 0.18s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -rs test_tmp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0\n",
      "Matplotlib: 3.5.2\n",
      "Freetype: 2.6.1\n",
      "rootdir: /home/ubuntu/ssinyu/FDB\n",
      "plugins: mock-3.10.0, mpl-0.16.1\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_tmp.py \u001b[33mx\u001b[0m\u001b[33ms\u001b[0m\u001b[33m                                                           [100%]\u001b[0m\n",
      "\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[33mXFAIL\u001b[0m test_tmp.py::\u001b[1mTestTrainModel::test_on_linear_data\u001b[0m - not implemented\n",
      "\u001b[33m======================== \u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m1 xfailed\u001b[0m\u001b[33m in 0.20s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -rx test_tmp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0\n",
      "Matplotlib: 3.5.2\n",
      "Freetype: 2.6.1\n",
      "rootdir: /home/ubuntu/ssinyu/FDB\n",
      "plugins: mock-3.10.0, mpl-0.16.1\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_tmp.py \u001b[33mx\u001b[0m\u001b[33ms\u001b[0m\u001b[33m                                                           [100%]\u001b[0m\n",
      "\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[33mSKIPPED\u001b[0m [1] test_tmp.py:11: requires python 3.7 or higher\n",
      "\u001b[33mXFAIL\u001b[0m test_tmp.py::\u001b[1mTestTrainModel::test_on_linear_data\u001b[0m - not implemented\n",
      "\u001b[33m======================== \u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m1 xfailed\u001b[0m\u001b[33m in 0.21s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -rsx test_tmp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "  \n",
    "## 4. Testing Models, Plots and Much More\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "* 파일을 입력받는 경우, 테스트를 위해 임시로 파일을 만들고 테스트 후 제거해야 한다  \n",
    "-> `@pytest.fixture` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_tmp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_tmp.py\n",
    "\n",
    "import os, pytest\n",
    "import numpy as np\n",
    "from as_numpy import get_data_as_numpy_array\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def clean_data_file():\n",
    "    file_path = \"clean_data_file.txt\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(\"201\\t305671\\n7892\\t298140\\n501\\t738293\\n\")   # setup\n",
    "    yield file_path\n",
    "    os.remove(file_path)                                      # teardown\n",
    "\n",
    "    \n",
    "def test_on_clean_file(clean_data_file):\n",
    "    expected = np.array([\n",
    "        [201.0, 305671.0], \n",
    "        [7892.0, 298140.0], \n",
    "        [501.0, 738293.0]\n",
    "    ])\n",
    "    actual = get_data_as_numpy_array(clean_data_file, 2)\n",
    "    assert actual == pytest.approx(expected), \"Expected: {0}, Actual: {1}\".format(expected, actual) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.13, pytest-7.2.0, pluggy-1.0.0\n",
      "Matplotlib: 3.5.2\n",
      "Freetype: 2.6.1\n",
      "rootdir: /home/ubuntu/ssinyu/FDB\n",
      "plugins: mock-3.10.0, mpl-0.16.1\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_tmp.py \u001b[32m.\u001b[0m\u001b[32m                                                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.18s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_tmp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "* 임시 디렉토리 `tmpdir` 사용하기\n",
    "    1. setup `tmpdir`\n",
    "    2. setup `tmpdir/{file}`\n",
    "    3. test\n",
    "    4. teardown `tmpdir/{file}`\n",
    "    5. teardown `tmpdir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def raw_and_clean_data_file(tmpdir):\n",
    "    raw_data_file_path = tmpdir.join(\"raw.txt\")\n",
    "    clean_data_file_path = tmpdir.join(\"clearn.txt\")\n",
    "    with open(raw_data_file_path, \"w\") as f:\n",
    "        f.write(\"1,801\\t201,411\\n\")\n",
    "    yield raw_data_file_path, clean_data_file_path\n",
    "\n",
    "    # teardown 알아서 수행됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>   \n",
    "\n",
    "* 함수 사이의 의존성에 관계 없이 테스트 수행  \n",
    "ex) `A()`의 출력이 `B()`의 동작에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(comma_separated_integer_string):\n",
    "    ...\n",
    "    # problem\n",
    "    ...\n",
    "\n",
    "def preprocess(raw_path, clean_path):\n",
    "    with open(raw_path, \"r\") as input_file:\n",
    "        rows = input_file.readlines()\n",
    "    \n",
    "    with open(clean_path, \"w\") as output_file:\n",
    "        for row in rows:\n",
    "            ...\n",
    "            result = convert_to_int(row)\n",
    "            ...\n",
    "            output_file.write()\n",
    "\n",
    "\n",
    "# ==> \n",
    "def convert_to_int_bug_free(comma_separated_integer_string):\n",
    "    return_values = {\n",
    "        \"1,801\": 1801, \"201,411\": 201411, \"2,002\": 2002, \n",
    "        \"333,209\": 333209, \"1990\": None, \"782,911\": 782911, \n",
    "        \"1,285\": 1285, \"389129\": None\n",
    "    }\n",
    "    return return_values[comma_separated_integer_string]\n",
    "\n",
    "\n",
    "from unittest.mock import call\n",
    "class TestPreprocess(object):\n",
    "    def test_on_raw_data(self, raw_and_clean_data_file, mocker):\n",
    "        raw_path, clean_path = raw_and_clean_data_file\n",
    "        convert_to_int_mock = mocker.patch(\n",
    "            \"data.preprocessing_helpers.convert_to_int\",\n",
    "            side_effect=convert_to_int_bug_free\n",
    "        )\n",
    "        preprocess(raw_path, clean_path)\n",
    "\n",
    "        with open(clean_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        first_line = lines[0]\n",
    "        assert first_line == \"1801\\t201411\\n\"\n",
    "        second_line = lines[1]\n",
    "        assert second_line == \"2002\\t333209\\n\"  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "* 모델 테스트\n",
    "    * 모델에 정확하게 맞는 데이터를 입력하고 출력값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "from models.train import model_test\n",
    "\n",
    "def test_on_perfect_fit():\n",
    "    test_argument = np.array([[1, 3], [2, 5], [3, 7]])\n",
    "    expected = 1\n",
    "    actual = model_test(test_argument, slope=2, intercept=1)\n",
    "    assert actual == pytest.approx(expected), \"Expected: {0}, Actual: {1}\".format(expected, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 플롯 테스트  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기본 구조\n",
    "```\n",
    "    src/\n",
    "    ├── data/\n",
    "    ├── features/\n",
    "    ├── models/\n",
    "    ├── visualization/\n",
    "    │        └── plots.py\n",
    "    │              └── get_plot_for_best_fit_line (function)\n",
    "    tests/\n",
    "    ├── data/\n",
    "    ├── features/\n",
    "    ├── models/\n",
    "    └── visualization/\n",
    "             └── test_plots.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex) $y=5x-2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.plots import get_plot_for_best_fit_line\n",
    "import pytest\n",
    "import numpy as np\n",
    "\n",
    "class TestGetPlotForBestFitLine(object):\n",
    "    @pytest.mark.mpl_image_compare\n",
    "    def test_plot_for_almost_linear_data(self):\n",
    "        slope = 5.0\n",
    "        intercept = -2.0\n",
    "        x_array = np.array([1.0, 2.0, 3.0])\n",
    "        y_array = np.array([3.0, 8.0, 11.0])\n",
    "        title = \"Test plot for almost linear data\"\n",
    "        return get_plot_for_best_fit_line(slope, intercept, x_array, y_array, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest -k \"test_plot_for_almost_linear_data\" --mpl-generate-pth visualization/baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 실행시 visualization/baseline/ 내 function 이름으로 png 파일 생성\n",
    "  \n",
    "```\n",
    "    src/\n",
    "    ├── data/\n",
    "    ├── features/\n",
    "    ├── models/\n",
    "    ├── visualization/\n",
    "    │        └── plots.py\n",
    "    │              └── get_plot_for_best_fit_line (function)\n",
    "    tests/\n",
    "    ├── data/\n",
    "    ├── features/\n",
    "    ├── models/\n",
    "    └── visualization/\n",
    "             ├── test_plots.py\n",
    "             └── baseline/\n",
    "                    └── test_plot_for_almost_linear_data.png\n",
    "             \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.mpl_image_compare\n",
    "def test_plot_for_almost_linear_data():\n",
    "    ...\n",
    "\n",
    "\n",
    "!pytest -k \"test_plot_for_almost_linear_data\" --mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* baseline 이미지 및 테스트 이미지가 일치하지 않는 영역이 흰색으로 나타남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot_diff](https://raw.githubusercontent.com/SSinyu/PlayGround/master/fig/plot_diff.PNG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9261bf8f9d8e3668338818b391eef31c2a58bf53a7417fc2295896dd5d901f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
